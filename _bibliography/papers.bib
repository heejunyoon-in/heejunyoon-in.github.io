---
---

@string{aps = {American Physical Society,}}


@thesis{thesis,
    author = {Heejun Yoon},
    title = {A Combined Twin and Single Network for Fast and Robust Inspection of IC Substrates},
    school = {Ewha Womans University},
    year = {2024},
    pdf={HJYoon_thesis_published.pdf},
    url={https://www.riss.kr/link?id=T17053834},
    slides={HJYoon_thesis_ppt_v3.pdf},
    preview={thumb_thesis.png},
    abstract={This thesis explores a novel approach to inspecting IC substrates by integrating twin and single network architectures for fast and accurate defect detection. For inspecting IC substrates, the repetitive nature of the substrates allows comparison-based inspection approaches that detect changed regions between test and reference images. This research proposes a hybrid approach of Combined Twin and Single Network (abbreviated by C-TSNet). We incorporate a single network that is not affected by misalignments and color variations with a twin network, the proposed network achieves robustness to mis-registration while maintaining low computational latency. Additionally, we introduce CC-TSNet, which is extended version of C-TSNet by adding a channel co-attention module to further improve robustness against characteristic differences.}
}

@inproceedings{2023UR,
  title={Personal Mobility Safe Driving System with Knowledge Distillation},
  author={Heejun Yoon* and Damin Yeom* and Soyeon Lee* and Kahyun Lee†},
  annotation={* Equal contribution<br>† Corresponding author},
  booktitle={2023 IEEE 20th International Conference on Ubiquitous Robots(UR)},
  year={2023},
  doi={10.1109/UR57808.2023.10202355},
  poster={UR2023_poster_final.pdf},
  url={https://ieeexplore.ieee.org/document/10202355},
  abstract={The global personal mobility market has been expanding rapidly due to its convenience. However, the rising number of accidents involving personal mobility devices, including falls, collisions, and incidents with moving vehicles or objects, has become a significant concern. In this paper, we propose a deep learning-based safe driving system that integrates both user and road images to address these safety issues. Our system leverages CNN-based models to simultaneously perform the following tasks: 1) detecting if the user is wearing a helmet, 2) ensuring the user is looking ahead, 3) identifying whether the scooter is being ridden on the sidewalk, and 4) recognizing proximity to intersections. These tasks operate in parallel to provide a comprehensive assessment of the driving environment. The system determines the scooter’s final speed by selecting the minimum speed value from all tasks to ensure maximum safety. Additionally, we utilize knowledge distillation techniques to compress the models, enabling real-time inference on edge devices. This approach delivers a fast, efficient, and highly accurate system, specifically tailored to the needs of personal mobility users.},
  preview={thumb_ur_demo.gif}
}

@inproceedings{2023IPIU,
  title={Action Recognition using 3D Point Cloud from Frequency Modulated Continuous Wave Radar Signals},
  author={Heejun Yoon and Jimin Park and Jeongtae Kim†},
  annotation={† Corresponding author},
  booktitle={2023 Image Processing and Image Understanding(IPIU)},
  pdf={IPIU2023_HJYoon_final_paper.pdf},
  poster={IPIU2023_poster.pdf},
  year={2023},
  abstract={In this paper, we generated three-dimensional point clouds based on Frequency Modulated Continuous Wave (FMCW) radar and performed object motion classification using Support Tensor Machine (STM). 3D Capon Beamforming was applied to the data acquired by the FMCW radar to generate a three-dimensional point cloud, which was then subsampled in half and converted to one-dimensional data to reduce computation. STM was applied to perform motion classification, and the motion was classified with 82% accuracy.},
  preview={thumb_IPIU.png}
}

@inproceedings{2022IEIE,
  title={2-input Deep Learning based Multi-tasking Safe Driving},
  author={Heejun Yoon* and Damin Yeom* and Soyeon Lee* and Kahyun Lee†},
  annotation={* Equal contribution<br>† Corresponding author},
  booktitle={Fall Annual Conference of The Institute of Electronics and Information Engineers (IEIE)},
  year={2022},
  publisher={IEIE},
  pdf={IEIE_paper.pdf},
  slides={presentation_for_IEIEpaper_competition.pdf},
  url={https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11195420},
  abstract={The rapid growth of electric scooter-sharing services has brought personal mobility devices into the spotlight. However, this rise in popularity has been accompanied by increasing public concern over e-scooter accidents. To address these safety challenges, we propose a deep learning-based safe driving system for electric scooters that analyzes both user and road images. Our framework employs CNN-based models to determine whether the user is wearing a helmet or maintaining proper forward vision by analyzing user images. Simultaneously, the system verifies if the scooter is on a designated road and estimates the distance between the user and the nearest pedestrian from road images. Finally, it calculates the scooter’s optimal velocity using the outputs from these models. By leveraging a fast and precise deep learning approach, our system enhances real-time decision-making and provides a high level of confidence in detecting and mitigating multiple hazards simultaneously.},
  preview={thumb_IEIE.png}
}


